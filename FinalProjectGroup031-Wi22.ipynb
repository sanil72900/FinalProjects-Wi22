{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video\n",
    "https://drive.google.com/file/d/1Jn3pSgIE1aye5TuL6EFp6uR7X6AJudox/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permissions\n",
    "\n",
    "Place an `X` in the appropriate bracket below to specify if you would like your group's project to be made available to the public. (Note that student names will be included (but PIDs will be scraped from any groups who include their PIDs).\n",
    "\n",
    "* [X] YES - make available\n",
    "* [  ] NO - keep private"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we investigate the relationship between health, education, and home security with crime rates and conclude that there is little correlation between health, education, home security with crime rates. We built linear regression lines using ordinary least-squares and visualized them using a scatter plot. By looking at the regression line and visualization, it turns out that crime rates have a weak negative correlation with health, education, and home security respectively. We then applied linear regression, radial basis function from support vector regression, polynomial from support vector regression, ridge, and poisson regression and concluded there is no relationship between our interests. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Jiahui Cai\n",
    "- Jacky Hu\n",
    "- Cody Li\n",
    "- Rosy Xu\n",
    "- Linghao Zhang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='research_question'></a>\n",
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there a relationship between health, education, and house security spending and all different categories of crime rates in all 441 valid FSIP areas in San Diego County?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='background'></a>\n",
    "\n",
    "## Background & Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What background information led to our research topic\n",
    "\n",
    "In Becker's Economic Theory of Crime (1968), he stated that people resort to crime only if the costs of committing the crime are lower than the benefits gained. However, it turns out that crime is much more prevalent among poor, disadvantaged neighborhoods than among wealthy and middle-class neighborhoods, even though those wealthier neighborhoods are more likely to have precious possessions. One potential reason for such an unexpected phenomenon could be found in the article \"Why Disadvantaged Neighborhoods are More Attractive Targets for Burgling than Wealthy Ones.\" The authors Alyssa W. Chamberlain and Lyndsay N.Boggess claimed that wealthier communities have lower burglary rates because burglars tend to live further away from and are unfamiliar with wealthier neighborhoods. Instead, they are more likely to target disadvantaged neighborhoods since they lived there, which lowers the risk for burglars to commit crimes (due to the familiarity). In reality, most people want to live in a \"safer\" neighborhood. Most \"safer\" neighborhoods tend to have relatively higher rents or housing prices. This type of motivation is also one of the reasons why people always associate the crime rate with the wealth level of the community. Since an individual's wealth level influences tons of decision-making, it is often measured by various factors, including salary, education expenditure, medical spending, debts, home security system spending, and other aspects. Among the above expenditures, health, education, and home security system spending in everyday life are some of the most critical factors determining one's wealth level. Therefore, in this project, we aim to find the relationship between the wealth level of communities - more specifically, the health, education, and home security system spending of people living in those communities - and the crime rate.\n",
    "\n",
    "Since a combination of other sub-factors determines wealth level, we decide to shrink the range from wealth level to expenditure on health, education, and home security system (as expenditure on these is often considered the most fundamental contributor to measuring one's wealth). From the report \"How does Health Spending in the U.S. Compared to Other Countries,\" we find that the United States spent about 11,946 dollars per capita on health consumption, far beyond any other country. Japan, for example, only has 4691 dollars per capita on health consumption, which is even less than half of the United States' spending. Based on this undeniable fact that the United States is the wealthiest country and has the highest GDP contribution in the entire world, we have concluded that medical spending could reflect the wealth level. In a similar approach, we observe that education plays a decisive role in economic performance. People with higher education levels often earn higher salaries compared to those with lower degrees of education. More generally, richer countries tend to have more educated populations, which also leads to economic growth at a national level. Furthermore, there are some parallels between home security and one’s financial performance since it is obvious that wealthy communities are safer, as people living there are more likely to spend money on home security systems. As a result, we believe that wealth health can be well reflected by spending on health, education, and home security systems. \n",
    "\n",
    "It is impossible to incorporate all the data of each sub-factor contributing to one's wealth level or determine an authoritative and exhaustive metric that fully represents the variable. We eventually decide to take health, education, and home security system spending to determine one's wealth level. We are also aware that there might be confounding variables in our study of finding the relationship between these three spending factors and the crime rate. Thus, determining such a relationship is only our first step, possibly with separate study cases for each confounding variable.\n",
    "\n",
    "\n",
    "### Why is this topic important\n",
    "\n",
    "A growing body of research has shown that most people with criminal records have serious health care needs, especially with a history of mental illness or psychological distress, as well as a lack of education. As a result, this prevalence of mental illness and lack of education in the criminal justice population has led the government to adopt the thinking that better access to health care and education helps reduce crime. Apart from that, it is not uncommon to acknowledge that crimes are much more prevalent among poor, disadvantaged neighborhoods than among wealthy and middle-class neighborhoods, where home security systems are better. While studies have proven that an increase in health, education, and home security system spending would cause a crime reduction, little research has been done focusing on the relationship between the three spending factors and the crime rate of communities.\n",
    "Taking it as our research interest, we believe that if we could find a relationship between them, we could utilize such findings to reduce the crime rate to the greatest extent by predicting the incidence of crime in each community. Therefore, governments or organizations can enact more restrictive laws and send more police force to those communities with higher estimates.\n",
    "\n",
    "In addition to the passive reduction of crimes, we could take advantage of this finding and solve the issue from the root. By discovering communities with significantly low health, education, and home security system spending, the government could open more treatment facilities, schools, and security offices in such areas and make related expenditures more affordable. With better access to health, education, and home security systems serving as the first step, we could gradually improve the entire community's well-being, both economically and socially.\n",
    "\n",
    "\n",
    "### Other concerns\n",
    "\n",
    "In addition, we notice that the distribution of wealth level is not normal (rather more right-skewed), whereas the distribution of three spendings is approximately normal. Therefore, in this project, it will be reasonable for us to use a normal distribution to approximate the spending on health, education, and home security systems.\n",
    "\n",
    "It is easy to find datasets about health, education, and home security system spending and criminal rate. Nevertheless, La Jolla is so small for us to get a large enough dataset (because most of the data are counted in a constituency). Thus, we decide to treat San Diego County as the base and choose our data within this larger range.\n",
    "\n",
    "Esri is one of the biggest data holders in the world. While it does not create or record data, it holds data for the federal government, state government, huge corporations, organizations, and individuals. ArcGIS Online is one of its tools for visualizing and manipulating its data. Taking advantage of its USA Census data and database, which contains detailed census data for every constituency, such as different crime indices, household income, and health information, we can establish different models and data frames to visualize. From that, comparisons between multiple categories can then be utilized to reveal the relationship between health, education, and home security system spending and crime rates.\n",
    "\n",
    "\n",
    "### References (include links):\n",
    "\n",
    "- 1) Esri official website - https://www.esri.com/en-us/home\n",
    "- 2) ArcGIS (UCSD) - https://ucsdonline.maps.arcgis.com/home/index.html\n",
    "- 3) U.S. Census Bureau - https://www.census.gov/data.html\n",
    "- 4) Why disadvantaged neighborhoods are more attractive targets for burgling than wealthy ones.\n",
    "https://blogs.lse.ac.uk/usappblog/2016/09/26/why-disadvantaged-neighborhoods-are-more-attractive-targets-for-burgling-than-wealthy-ones/\n",
    "- 5) How does Health Spending in the U.S. Compare to Other Countries https://www.healthsystemtracker.org/chart-collection/health-spending-u-s-compare-countries-2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis:\n",
    "\n",
    "The higher the average household health / education / home security system spending the sector has, the lower the crime rate sector has.\n",
    "\n",
    "### Defence:\n",
    "\n",
    "- 1) The higher spending a household has, the higher income a household has. For a household with a higher income, it is less likely to violate the law, which means a lower crime rate.\n",
    "- 2) The more spending a household has on health, education, and home security systems, the more the household cares about their health, education, and home security system issues. Thus, they will not easily commit a crime since crime brings up risks detrimental to what they care about.\n",
    "- 3) The higher health, education, and home security system spending a household has, the richer their communities are. In general, a rich community would likely spend much money on security, which causes a lower crime rate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Information\n",
    "- Dataset Name: ArcGIS San Diego Health Spending and Crime Data\n",
    "- Link to the dataset: https://ucsdonline.maps.arcgis.com/home/item.html?id=f17532d8cc53447680bd641de3365ce2\n",
    "- Number of observations: 736\n",
    "\n",
    "### Description:\n",
    "- Dataset Name: ArcGIS-Health-Crime-Data.csv\n",
    "- 736 observations\n",
    "- 44 variables\n",
    "\n",
    "This dataset provides information about general health care spending, educational spending, and home security system services in San Diego county in 2021. It also includes data describing the crime rate in the same year, including crimes such as murder, rape, robbery, assault, property crime, burglary, larceny, and motor vehicle theft. This dataset will be used to determine whether the community’s spending on the above three categories (general health care, education, and home security system services) is associated with (particularly with an antagonistic relationship) the crime rate in the community."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you did not install the packages of plotly and sklearn, please run the cell below to install the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# install packages\n",
    "!pip install plotly\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better perform our data analysis task and answer our research question, additional functionalities outside what is included in Python by default are required. We import the following useful packages using their common shortened names (i.e., patsy, NumPy, pandas, seaborn, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import patsy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "# Import packages\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Statical package\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Panda Version package\n",
    "from pandas import to_datetime\n",
    "from pandas import DatetimeIndex\n",
    "from pandas import Period\n",
    "\n",
    "# Configure libraries\n",
    "sns.set(context = 'talk', style='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below script will get us the dataset needed to run this Jupiter notebook. Since we have a CSV file ready on Github for our Spending-Crime Data, we can directly import the data file using the URL. We import our dataset into a DataFrame called df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/RecluseHermit/COGS-108-Group-31-Data-Set/main/ArcGIS-Spendings-Crime-Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our research questions focus on whether there is a relationship between health, education, and house security spending and all different categories of crime rate in all 535 valid FSIP areas in San Diego County, we are only interested in variables relative to health, education, housing security, and crime. Thus, the first step in data cleaning is only to extract or include information about these four significant variables. As a result, we have decided to remove other irrelevant or useless columns, including county, state, ID, country code, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop useless columns\n",
    "df = df.drop(columns = ['OBJECTID', 'FIPS', 'SQMI',\n",
    "                        'COUNTY', 'STATE', 'Id', 'Country code', 'ENRICH_FID',\n",
    "                        'Aggregation method', 'Population to polygon size rating for the country',\n",
    "                        'Apportionment confidence for the country', 'Has data',\n",
    "                        'Invalid1', 'Invalid2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing all missing information, we look at all of the columns. Since some of the variable names are relatively long compared to others, we decided to rename all of them into a more standard form. We create a function called col_clean (with input parameter as a string) that helps us standardize the messy column titles. After applying the standardized method, our new column names are presented in lowercase letters with the underline separating each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN \n",
    "df = df.dropna(subset = ['POP2020'])\n",
    "df = df.drop(columns = ['POP2020'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After observing the current dataset (excluded all useless columns), we have found that there exist some missing values under the POP2020 column. Since there is no population identified in those areas with missing values, it is not meaningful to include such areas with its corresponding values (health, education, and housing security) spending information. Therefore, to prevent them from leading biases and outliers in our analysis output, we have decided to remove all the rows that contain missing values. After this, we do the POP2020 column anymore, so we droped it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title Cleaning\n",
    "def col_clean(str_in):\n",
    "    str_in = str_in.lower()\n",
    "    str_in = str_in.strip()\n",
    "    \n",
    "    # since all our data is from 2021, we remove 2021 from the title of data\n",
    "    str_in = str_in.replace('2021', '')\n",
    "    str_in = str_in.replace('2020', '')\n",
    "    \n",
    "    # remove ':' from different data of spendings and crimes\n",
    "    str_in = str_in.replace(':', '')\n",
    "    str_in = str_in.strip()\n",
    "    \n",
    "    # we turn title into snake variable\n",
    "    str_in = str_in.replace(' ', '_')\n",
    "    str_in = str_in.strip()\n",
    "    \n",
    "    # return after clean title\n",
    "    return str_in\n",
    "\n",
    "# Apply Cleaning\n",
    "new_columns = df.columns\n",
    "new_columns_name = []\n",
    "\n",
    "# Create new list to put the after clean title in\n",
    "for title in new_columns:\n",
    "    new_columns_name.append(col_clean(title))\n",
    "    \n",
    "# New Title\n",
    "df.columns = new_columns_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check our dataframe again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the Dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to have an overview of each varaible in df dataset, thus we use the describe method to get the descriptive statistics for all variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Summarize the data in the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After briefly cleaning the dataset, we apply the plot the overall distribution for each variable of our interest. By plotting histograms for average health care spending, average education spending, average home security system services spending, and total crime aggregate, we could have a better idea of what the distributions look like visually. The graph below shows that all four distributions are approximately normal, but a little bit skew to right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check the distributions and see if there are any outliers\n",
    "plt.rcParams['figure.figsize'] = [20, 20]\n",
    "f, axes = plt.subplots(2,2)\n",
    "\n",
    "# check the distribution of health care average\n",
    "sns.histplot(data = df, x = \"avg_health_care\", stat = \"count\", ax = axes[0][0])\n",
    "\n",
    "# check the distribution of education average\n",
    "sns.histplot(data = df, x = \"avg_education\", stat = \"count\", color = '#b3cde3', ax=axes[0][1])\n",
    "\n",
    "# check the distribution of home security system svcs average\n",
    "sns.histplot(data = df, x = \"avg_home_security_system_svcs\", stat = \"count\", color = '#88419d', ax = axes[1][0])\n",
    "\n",
    "# check the distribution of total crime aggregate\n",
    "sns.histplot(data = df, x = \"total_crime_aggregate\", stat = \"count\", color = '#cbc9e2', ax = axes[1][1])\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the graphs above, there are some outliers on the far right end of the distributions for all histograms. We define the data as outliers if they are at least two standard deviations away from the mean. While outliers can sometimes be very informative about the data collection process, they can also increase the variability in our data, which leads to a decrease in the statistical power. Furthermore, removing outliers could reduce the least square error in our regression analysis, causing our results to become more valid. Due to the above justifications, we have found the outliers of avg_health_care, avg_education, avg_home_security_system_svcs, and total_crime_aggregate and removed them from our dataset. We remove the outliers from crime aggregate because we lack the data of the average for crime rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the graph, it seems that there are some outliers on the right of the distributions. \n",
    "# We define outlier if it is 2 standard deviations away the mean and remove them\n",
    "df = df[df['avg_health_care'] <= df.get(\"avg_health_care\").mean() + 2 * np.std(df.get(\"avg_health_care\"))]\n",
    "df = df[df['avg_health_care'] >= df.get(\"avg_health_care\").mean() - 2 * np.std(df.get(\"avg_health_care\"))]\n",
    "\n",
    "df = df[df['avg_education'] <= df.get(\"avg_education\").mean() + 2 * np.std(df.get(\"avg_education\"))]\n",
    "df = df[df['avg_education'] >= df.get(\"avg_education\").mean() - 2 * np.std(df.get(\"avg_education\"))]\n",
    "\n",
    "df = df[df['avg_home_security_system_svcs'] <= df.get(\"avg_home_security_system_svcs\").mean() \n",
    "        + 2 * np.std(df.get(\"avg_home_security_system_svcs\"))]\n",
    "df = df[df['avg_home_security_system_svcs'] >= df.get(\"avg_home_security_system_svcs\").mean() \n",
    "        - 2 * np.std(df.get(\"avg_home_security_system_svcs\"))]\n",
    "\n",
    "df = df[df['total_crime_aggregate'] <= df.get(\"total_crime_aggregate\").mean() \n",
    "        + 2 * np.std(df.get(\"total_crime_aggregate\"))]\n",
    "df = df[df['total_crime_aggregate'] >= df.get(\"total_crime_aggregate\").mean() \n",
    "        - 2 * np.std(df.get(\"total_crime_aggregate\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph the aftermath\n",
    "plt.rcParams['figure.figsize'] = [20, 20]\n",
    "f, axes = plt.subplots(2,2)\n",
    "\n",
    "# check the distribution of health care\n",
    "sns.histplot(data = df, x = \"health_care\", stat = \"count\", ax = axes[0][0])\n",
    "\n",
    "# check the distribution of education\n",
    "sns.histplot(data = df, x = \"education\", stat = \"count\", color = '#b3cde3', ax=axes[0][1])\n",
    "\n",
    "# check the distribution of home security system svcs\n",
    "sns.histplot(data = df, x = \"home_security_system_svcs\", stat = \"count\", color = '#88419d', ax = axes[1][0])\n",
    "\n",
    "# check the distribution of total crime aggregate\n",
    "sns.histplot(data = df, x = \"total_crime_aggregate\", stat = \"count\", color = '#cbc9e2', ax = axes[1][1])\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing the outliers, we perform data standardization that puts different variables on the same scale and allows us to do further analysis. Following the standardized test statistic for z-scores, we have transformed each value into the value itself subtracted by the mean and then divided by the standard deviation. In the end, we assign these new values back into t_standardized_data and save them for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the graphs, we could see that the distribution of health care, education, home security system svcs, \n",
    "# and total crime aggregate are approximately normal, though a bit right skewed. Besides, the counts are more\n",
    "# than 500. Thus, we standardize the health care, education, home security system svcs, and total crime aggregate.\n",
    "def standardized_units(data):\n",
    "    mean_value = data.mean()\n",
    "    std_value = np.std(data)\n",
    "    lst = []\n",
    "    \n",
    "    for each_data in data:\n",
    "        lst.append((each_data - mean_value) / std_value)\n",
    "        \n",
    "    return lst\n",
    "\n",
    "# apply the standardization\n",
    "t_standardized_data = pd.DataFrame().assign(\n",
    "    t_standardized_healthcare = standardized_units(df.get(\"health_care\")),\n",
    "    t_standardized_education = standardized_units(df.get(\"education\")),\n",
    "    t_standardized_home_security = standardized_units(df.get(\"home_security_system_svcs\")),\n",
    "    t_standardized_crime = standardized_units(df.get(\"total_crime_aggregate\")),\n",
    ")\n",
    "\n",
    "# check the standardized data\n",
    "t_standardized_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis & Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we already cleaned our dataset by removing all irrelevant columns, missing values, and outliers as well as performing the z-score standardization in the Data Cleaning section, now we can finally start analyzing our data.\n",
    "\n",
    "To better visualize our clean data on health care spending, education spending, home security system service spending, and total crime aggregate, we apply the sns.histoplot command to plot the overall distribution for each of them. \n",
    "\n",
    "However, as we have observed from the previous four histograms, the range of the x-axis appears to be extremely large. (For health care spending, the range lies in between 0 to 25,000,000 dollars; for education spending, the range lies in between 0 to 8,000,000 dollars; for home security system spending, the range lies in between 0 to 175,000 dollars; for total crime aggregate, the range lies in between 0 to 800,000). \n",
    "\n",
    "Therefore, to make the histograms more reader-friendly, we decide to rescale the x-axis by changing the units. For the health_care_standardized histogram, we rescale the x-axis with units in 1 million dollars. For the education_standardized histogram, we rescale the x-axis with units in 1,000 dollars. For the home_security_standardized histogram, we rescale the x-axis with units in 1,000 dollars. For the aggregate_crime_standardized histogram, we rescale the x-axis with units in 1,000.\n",
    "\n",
    "After plotting the four histograms, we can observe that they now look much more readable compared to the ones before applying the unit change. Meanwhile, since we’re using the same dataset (with a slight change in units), the graphs still preserve the same approximately normal distributions. From a statistical point of view, this normal distribution makes sense due to the central limit theorem, a probability theory which states that the distribution of a sample variable approximates a normal distribution as the sample size becomes larger. In our case, since the sample size is large enough, the central limit theorem indeed holds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution graph\n",
    "\n",
    "# Assign standardized value to the dataframe\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "df = df.assign(\n",
    "    health_care_standardized = df.get(\"health_care\") / 1000000,\n",
    "    education_standardized = df.get(\"education\") / 1000,\n",
    "    home_security_standardized = df.get(\"home_security_system_svcs\") / 1000,\n",
    "    aggregate_crime_standardized = df.get(\"total_crime_aggregate\") / 1000\n",
    ")\n",
    "\n",
    "# Plot healthcare distribution graph\n",
    "fig_healthcare = sns.histplot(data = df, x = \"health_care_standardized\", stat = \"count\", bins = 20)\n",
    "fig_healthcare.set_xlabel(\"health care with units 1M\")\n",
    "fig_healthcare.set(title = \"Histogram of Health Care\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot education distribution graph\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "fig_education = sns.histplot(data = df, x = \"education_standardized\", stat = \"count\", color = '#b3cde3')\n",
    "fig_education.set_xlabel(\"education with units 1k\")\n",
    "fig_education.set(title = \"Histogram of Education\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot homesecurity distribution graph\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "fig_homesecurity = sns.histplot(data = df, x = \"home_security_standardized\", stat = \"count\",color = '#88419d')\n",
    "fig_homesecurity.set_xlabel(\"home_security with units 1k\")\n",
    "fig_homesecurity.set(title = \"Histogram of Home Security System\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot aggregate crime distribution graph\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "fig_aggregate_crime = sns.histplot(data = df, x = \"aggregate_crime_standardized\", stat = \"count\", color = '#cbc9e2')\n",
    "fig_aggregate_crime.set_xlabel(\"aggregate_crime with units 1k\")\n",
    "fig_aggregate_crime.set(title = \"Histogram of Aggregate Crime\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the above figures provide us with a brief visualization of our dataset by displaying the overall distributions of the major four variables of interest (health care spending, education spending, home security system service spending, total crime aggregate), we still need further analysis to investigate the relationship between them.\n",
    "\n",
    "As we learned in class, scatterplots are best used to determine whether or not two variables have a relationship or correlation. Besides, since all of our values are ratio scales, we can then pick two variables each time and plot them on a scatter diagram to view their relationship.\n",
    "Recall that our research question focuses on whether there is a relationship between health, education, and house security system service spending and all different categories of crime rate in all 535 valid FSIP areas in San Diego County. That is, we are mostly interested in the correlation between each of the three spending variables and the crime rate.\n",
    "\n",
    "Thus, in the below script, we apply the sns.regplot command to generate three scatterplots (each plot with a corresponding least-squared regression line) that indicate the relationship between each factor and the total crime aggregate: health care spending vs. total crime aggregate, education spending vs. total crime aggregate, and home security system spending vs. total crime aggregate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot of the aggregate values\n",
    "plt.rcParams['figure.figsize'] = [14, 17]\n",
    "\n",
    "# Extract the columns that we want to analyze\n",
    "overall_total = df[['health_care', 'education', 'home_security_system_svcs', 'total_crime_aggregate']]\n",
    "f, axes = plt.subplots(3,1)\n",
    "f.suptitle('Relationship between each factors and total crime aggregate', fontsize=20)\n",
    "factors_total = ['health_care', 'education', 'home_security_system_svcs']\n",
    "\n",
    "# Plotting\n",
    "sns.regplot(y='total_crime_aggregate', x=factors_total[0], data=overall_total, ax=axes[0])\n",
    "sns.regplot(y='total_crime_aggregate', x=factors_total[1], data=overall_total, ax=axes[1], color = '#b3cde3')\n",
    "sns.regplot(y='total_crime_aggregate', x=factors_total[2], data=overall_total, ax=axes[2], color = '#88419d')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After taking a closer look at each scatterplot, though the points seem to be random, by drawing the regression line, we observe a slight negative slope between each of the three factors and the total crime aggregate. This implies that the more spending on health care, education, and home security system in a valid FSIP area in San Diego County, the less total crime aggregate in that same area. This discovery also makes sense intuitively because, in reality, crime is much more prevalent among poor, disadvantaged neighborhoods (with less spending on health care, education, and home security system) than among wealthy and middle-class neighborhoods (with more spending on health care, education, and home security system). With such background knowledge, we could verify that our conclusion drawn from the below scatterplots makes sense.\n",
    "\n",
    "From the three OLS regression model, we find that though all three graphs indicate negative slope, the R-squared for all three models are very small.\n",
    "\n",
    "To extract more evidence that supports our previous claim, we would like to further investigate the correlation between each of the three factors and the total crime aggregate. This time, we use the standardized data from the t_standardized_data created in the Data Cleaning section. \n",
    "\n",
    "Similar to the linear pattern in the above scatterplots on “unstandardized” data, we again observe a slight negative slope between each of the three factors and the t standardized crime. If we take a more careful look at each scatterplot, we notice that the slopes of the regression lines of corresponding scatterplots are exactly the same (unstandardized data vs. standardized data) since we use the same dataset only with a rescale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot after standardized data\n",
    "plt.rcParams['figure.figsize'] = [14, 17]\n",
    "\n",
    "# Extract the columns that we want to analyze\n",
    "f, axes = plt.subplots(3,1)\n",
    "f.suptitle('Relationship between each factors and total crime aggregate', \n",
    "           fontsize=20)\n",
    "factors_standardized = ['t_standardized_healthcare', 't_standardized_education', 't_standardized_home_security']\n",
    "\n",
    "# Plotting\n",
    "sns.regplot(y='t_standardized_crime', x=factors_standardized[0], data=t_standardized_data, ax=axes[0])\n",
    "sns.regplot(y='t_standardized_crime', x=factors_standardized[1], data=t_standardized_data, ax=axes[1], color = '#b3cde3')\n",
    "sns.regplot(y='t_standardized_crime', x=factors_standardized[2], data=t_standardized_data, ax=axes[2], color = '#88419d')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the three OLS regression model, we find that though all three graphs indicate negative slope, the R-squared for all three models are very small.\n",
    "\n",
    "Next, we will further investigate the correlation between each of the three factors and the total crime aggregate using index values provided in the dataset. The index for each variable provides a view of the relative proportion of the value with respect to the entire population. For example, the overall crime index is based on the crime rate per certain (e.g. 10,000) population for all crimes in a specific area. Compared to the linear pattern in the scatterplots above, we now observe an even stronger negative correlation between each of the three factors and the total crime index, meaning that one unit increase in index of health care, education, or home security would mostly likely to decrease total crime index. Thus, plotting with the index values makes the relationship more distinct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [14, 17]\n",
    "\n",
    "# Extract the columns that we want to analyze\n",
    "overall = df[['index_health_care', 'index_education', 'index_home_security_system_svcs', 'total_crime_index']]\n",
    "f, axes = plt.subplots(3,1)\n",
    "f.suptitle('Relationship between each factors and total crime aggregate', \n",
    "           fontsize=20)\n",
    "factors_index = ['index_health_care', 'index_education', 'index_home_security_system_svcs']\n",
    "sns.regplot(y='total_crime_index', x=factors_index[0], data=overall, ax=axes[0])\n",
    "sns.regplot(y='total_crime_index', x=factors_index[1], data=overall, ax=axes[1], color = '#b3cde3')\n",
    "sns.regplot(y='total_crime_index', x=factors_index[2], data=overall, ax=axes[2], color = '#88419d')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also make three OLS regressions for index of health care v.s. total crime index, education index v.s. total crime index, and home security index v.s. total crime index. We found that the slope is more negative and R-square is higher than previous models. This implies that the models with index is more reliable compared with previous two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above nine scatterplots all display a solidly negative correlation between each of the three factors (health care, education, and home security system service spending) and the crime rate. As a result, it’s reasonable for us to draw the conclusion that the more spending on health care, education, and home security system in a valid FSIP area in San Diego County, the less total crime aggregate in that same area.\n",
    "\n",
    "While we have reached the general conclusion as stated above, it is even better for us to further investigate how each of the three factors (health care, education, and home security system service spending) contributes to the nine different crime aggregates (i.e. murder, personal crime, rape, robbery, assault, property crime, burglary, larceny, and motor vehicle theft). To accomplish this, we will use line plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement the function that is used for split each datapoint into a interval\n",
    "def split_crime(data):\n",
    "    mean_value = data.sum() / len(data)\n",
    "    std_value = np.std(data)\n",
    "    std_value_divided_4 = std_value / 4\n",
    "    lst = []\n",
    "    for each in data:\n",
    "        temp = each - mean_value\n",
    "        if temp < 0:\n",
    "            temp += 1\n",
    "        lst.append((int(temp / std_value_divided_4) + 0.5) * std_value_divided_4 + mean_value)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line charts are best when we want to show how certain value changes over time or compare how several things change over time relative to each other. That being said, since we are trying to investigate how the nine different crime aggregates are impacted by health care spending, education spending, and home security system spending, we can take advantage of the nice properties of the line chart. We can set each of the spending factors as the x-axis and the crime aggregates as the y-axis, thereby plotting nine lines with different colors (each representing a specific type of crime) on the chart.\n",
    "\n",
    "However, we will encounter a problem while plotting the line chart. Since we have a relatively large dataset, it contains tons of unique spending values, which represent the x values in the line chart. As a result, if we use our original data to plot the line chart, it will almost look like an abnormal ECG with more than 500 data points connecting together. In other words, the chart will be full of details such that we are unable to perceive the overall trend of each line at all.\n",
    "\n",
    "To solve this problem, we decide to write a function called split_crime that helps us round down the values on the x-axis and eventually reduce the number of x values. To put it more simply, we try to combine several x values that are close to each other and make them share the same y value. To achieve this, we set each x value to be equal to itself subtracted by the mean, divided by the standard deviation over 4, added by 0.5, multiplied with the standard deviation over 4, and finally added by the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reassign the columns into dataframe.\n",
    "temp = df.get(\"health_care\")\n",
    "df = df.assign(health_care_roundown = split_crime(temp))\n",
    "temp = df.get(\"education\")\n",
    "df = df.assign(education_roundown = split_crime(temp))\n",
    "temp = df.get(\"home_security_system_svcs\")\n",
    "df = df.assign(home_security_system_svcs_roundown = split_crime(temp))\n",
    "temp = df.get(\"index_health_care\")\n",
    "df = df.assign(index_health_care_roundown = split_crime(temp))\n",
    "temp = df.get(\"index_education\")\n",
    "df = df.assign(index_education_roundown = split_crime(temp))\n",
    "temp = df.get(\"index_home_security_system_svcs\")\n",
    "df = df.assign(index_home_security_system_svcs_roundown = split_crime(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement function which draws the lineplot for total crime aggregate and spending.\n",
    "def draw_graph_with_aggregate(spending):\n",
    "    # drawing the lineplot to display relationship between healthcare and 9 crimes in total\n",
    "    plt.rcParams['figure.figsize'] = [10, 10]\n",
    "    p = sns.lineplot(x = spending, y = \"murder_aggregate\", data = df, ci = None)\n",
    "# 9 specific crimes\n",
    "    sns.lineplot(x = spending, y = \"personal_crime_aggregate\", data = df, ci = None)\n",
    "    sns.lineplot(x = spending, y = \"rape_aggregate\", data = df, ci = None)\n",
    "    sns.lineplot(x = spending, y = \"robbery_aggregate\", data = df, ci = None)\n",
    "    sns.lineplot(x = spending, y = \"assault_aggregate\", data = df, ci = None)\n",
    "    sns.lineplot(x = spending, y = \"property_crime_aggregate\", data = df, ci = None)\n",
    "    sns.lineplot(x = spending, y = \"burglary_aggregate\", data = df, ci = None)\n",
    "    sns.lineplot(x = spending, y = \"larceny_aggregate\", data = df, ci = None)\n",
    "    sns.lineplot(x = spending, y = \"motor_vehicle_theft_aggregate\", data = df, ci = None)\n",
    "    p.set_ylabel(\"9 crimes aggregate\", fontsize = 20)\n",
    "    plt.legend(labels=[\"murder\",\"personal crime\", \"rape\", \"robbery\", \"assault\", \\\n",
    "                   \"property crime\", \"burglary\", \"larceny\", \"motor vehicle theft\"], loc = \"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Health care and total crime aggregate graph\n",
    "draw_graph_with_aggregate(\"health_care_roundown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Education and total crime aggregate graph\n",
    "draw_graph_with_aggregate(\"education_roundown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Home security and total crime aggregate graph\n",
    "draw_graph_with_aggregate(\"home_security_system_svcs_roundown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After rescaling the x values, we apply the sns.lineplot command to plot the line chart for each of the three factors (health care, education, and home security system service spending) over the nine different crime aggregates. As shown below, all three charts share similar patterns: crimes including motor vehicle theft, robbery, assault, personal crime, and murder all achieve their peak aggregates at approximately the same place (around 6000000 dollars spending on health care, around 2,000,000 dollars spending on education, around 27,000 dollars spending on home security system service) and then gradually decrease as spending increases. This finding matches our conclusion drawn from the scatterplots (the more spending on health care, education, and home security system in a valid FSIP area in San Diego County, the less total crime aggregate in that same area)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further investigate the impact of each of the three factors (health care, education, and home security system service spending) on the nine different crime aggregates, we perform the same visual analysis (i.e. plotting line charts) using the 9 crime index value. To correspond to the crime index, we used the index of health care, the index of education, and the index of security system service. This time, we have found a much stronger decreasing trend between our factors and crime index. Similar to the previous three graphs, we found that the motor vehicle yields the highest crime index among the three graphs, and the murder index yields the lowest crime index among the three graphs. Overall, when health care, education, and home security system spending increases, all nine different types of crime index decrease, despite the slower decreasing trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement function which draws the lineplot for total crime index and spending index.\n",
    "def draw_graph_with_index(spending):\n",
    "    plt.rcParams['figure.figsize'] = [10, 10]\n",
    "# 9 specific crimes\n",
    "    p4 = sns.lineplot(x = spending, y = \"murder_index\", data = df, ci = None)\n",
    "    sns.lineplot(x = spending, y = \"personal_crime_index\", data = df, ci = None)\n",
    "    sns.lineplot(x = spending, y = \"rape_index\", data = df, ci = None)\n",
    "    sns.lineplot(x = spending, y = \"robbery_index\", data = df, ci = None)\n",
    "    sns.lineplot(x = spending, y = \"assault_index\", data = df, ci = None)\n",
    "    sns.lineplot(x = spending, y = \"property_crime_index\", data = df, ci = None)\n",
    "    sns.lineplot(x = spending, y = \"burglary_index\", data = df, ci = None)\n",
    "    sns.lineplot(x = spending, y = \"larceny_index\", data = df, ci = None)\n",
    "    sns.lineplot(x = spending, y = \"motor_vehicle_theft_index\", data = df, ci = None)\n",
    "    p4.set_ylabel(\"9 crimes index\", fontsize = 20)\n",
    "    plt.legend(labels=[\"murder\",\"personal crime\", \"rape\", \"robbery\", \"assault\", \\\n",
    "                   \"property crime\", \"burglary\", \"larceny\", \"motor vehicle theft\"], loc = \"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Health care index and total crime index graph\n",
    "draw_graph_with_index(\"index_health_care_roundown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Education index and total crime index graph\n",
    "draw_graph_with_index(\"index_education_roundown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Home security index and total crime index graph\n",
    "draw_graph_with_index(\"index_home_security_system_svcs_roundown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other than drawing the scatterplot, we also applied ordinary least squares regression to mathematically compute the slope and p-value. We claim that the confidence interval is 5% and the null hypothesis be slope is 0. In other words, if p-value is less than 5%, we will have sufficient evidence to reject the null hypothesis and thus claim there is a correlation between the dependent variable and the independent variable. \n",
    "Since we are interested in if there is a correlation between education, healthcare, and home security on crime rate, we first study if each variable will be correlated to the crime rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the intercept and slope of linear regression line between each factor and standardized crime aggregate\n",
    "for i in range(len(factors_standardized)):\n",
    "    string = \"t_standardized_crime ~ \" + factors_standardized[i]\n",
    "    print(string)\n",
    "    dependent, predictor = patsy.dmatrices(string, t_standardized_data)\n",
    "    model = sm.OLS(dependent, predictor)\n",
    "    res_1 = model.fit()\n",
    "    print(res_1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the p-values for each regression model is less than 5%, the model suggests that there exists correlations between standardized crime and standardized healthcare, standardized education, and standardized home security respectively. From the summary, the slopes for three regression models are approximately around -0.20, meaning there is a negative correlation. Besides, increasing 1 standard deviation of independent variable would decrease dependent variable by 17% of standard deviation. Thus, these models are statistically and economically significant. However, the R-square in three models is around 0.03, meaning 3% of data could be explained by these models. This makes sense because there are a lot of factors contributing to crime rate, using only one factor to determine the crime rate by linear regression is not plausible. In conclusion, though the model shows that there are slight negative correlations between standardized crime and standardized healthcare, standardized education, and standardized home security respectively, the linear regression model with a single independent variable might not be the perfect model to predict crime rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the intercept and slope of linear regression line between each factor and total crime index\n",
    "for i in range(len(factors_index)):\n",
    "    string = \"total_crime_index ~ \" + factors_index[i]\n",
    "    print(string)\n",
    "    dependent, predictor = patsy.dmatrices(string, overall)\n",
    "    model = sm.OLS(dependent, predictor)\n",
    "    res_1 = model.fit()\n",
    "    print(res_1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then run the linear regressions on the crime rate index with the healthcare index, education index, and home security index respectively. We found that the p-value for all three slopes are approximately 0, meaning that we are strongly confident to reject the null hypothesis. The regression models suggest the slopes are around -0.4 to -0.6, representing there are weak negative correlations in our models. Besides, increasing 1 standard deviation of the independent variable would decrease the dependent variable by 45%. Thus, these models are statistically and economically significant. Compared with the previous tests, when we used standardized aggregate data, we now have R-square at around 20%. Thus, it seems that it is more reasonable to use index data to build our model compared to standardized.\n",
    "We then assign two of the variables in [healthcare, education, and home security] and investigate if any combination of two independent variables will influence the crime rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get the intercept and slope of linear regression line between each factor and standardized crime aggregate\n",
    "for i in range(len(factors_standardized)):\n",
    "    string = \"t_standardized_crime ~ \" + factors_standardized[i] + \" + \" + factors_standardized[(i+1)%len(factors_standardized)]\n",
    "    print(string)\n",
    "    dependent, predictor = patsy.dmatrices(string, t_standardized_data)\n",
    "    model = sm.OLS(dependent, predictor)\n",
    "    res_1 = model.fit()\n",
    "    print(res_1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the p-values for regression model of t_standardized_crime ~ t_standardized_healthcare + t_standardized_education and t_standardized_crime ~ t_standardized_education + t_standardized_home_security is larger than 5%, suggesting that we do not have enough evidence to reject null hypothesis. Thus we cannot indicate any correlations from these two regression models. In the last model, t_standardized_crime ~ t_standardized_home_security + t_standardized_healthcare, it suggests correlations between standardized crime, standardized healthcare, and standardized home security respectively. From the summary, we found that the p-value for both home security and healthcare are 0, so there is a correlation between crime, healthcare and home security. We also find the slope of home security is -1.133 and slope of healthcare is 0.9466. Since the R-square is 0.078, which means only 7.8% of data could be explained by this model, this regression model could not predict real-world crime rate well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get the intercept and slope of linear regression line between each factor and total crime index\n",
    "for i in range(len(factors_index)):\n",
    "    string = \"total_crime_index ~ \" + factors_index[i]  + \" + \" + factors_index[(i+1)%len(factors_index)]\n",
    "    print(string)\n",
    "    dependent, predictor = patsy.dmatrices(string, overall)\n",
    "    model = sm.OLS(dependent, predictor)\n",
    "    res_1 = model.fit()\n",
    "    print(res_1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then calculate the regression models for index. In each regression, there is only one variable with 0 p-value and one variable whose p-value is larger than 5%. In specific, the p-value of health care in either model is 0, suggesting there is a correlation between health care index and crime rate index. Since none of the regression models have 0 p-values for both variables, there is little meaningful analysis in this part.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the intercept and slope of linear regression line between 3 spendings and total crime aggregate\n",
    "string = \"t_standardized_crime ~ \" + factors_standardized[0] + \" + \" +\\\n",
    "factors_standardized[1] + \" + \" + factors_standardized[2]\n",
    "print(string)\n",
    "dependent, predictor = patsy.dmatrices(string, t_standardized_data)\n",
    "model = sm.OLS(dependent, predictor)\n",
    "res_1 = model.fit()\n",
    "print(res_1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the p-value of the intercept in the regression model of t_standardized_crime ~ t_standardized_healthcare + t_standardized_education + t_standardized_home_security is equal to 1, this does not significantly contribute to the analysis of the statistics. However, since all other p-values are less than 5%, the model suggests that there exists a correlation between standardized crime and standardized healthcare, standardized education, and standardized home security. From the summary, the slope for the t_standardized_healthcare is 1.8137, indicating a positive correlation between the crime rate and health spending. Meanwhile, the slopes for the other two variables range from -0.5789 to -1.4491, indicating that there exists a negative correlation. Overall, since there exist both positive and negative correlations between the crime rate and the three variables, the model does not suggest a strong one-directional (negative) relationship between our variables. In addition, the R-square in this model is 0.098, meaning 1% of the data could be explained by these models. In conclusion, this linear regression model with three independent variables only suggests a very weak negative correlation between our independent variables and dependent variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#get the intercept and slope of linear regression line between 3 spendings index and total crime index\n",
    "string = \"total_crime_index ~ \" + factors_index[0] + \" + \" +\\\n",
    "factors_index[1] + \" + \" + factors_index[2]\n",
    "print(string)\n",
    "dependent, predictor = patsy.dmatrices(string, overall)\n",
    "model = sm.OLS(dependent, predictor)\n",
    "res_1 = model.fit()\n",
    "print(res_1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then run the linear regressions on the crime rate index with index_health_care, index_education, and index_home_security. Compared to the linear regression model for standardized variables, R-squared is 15% larger, which means our index model can represent 15% more of the actual data. We found that the p-value for all three slopes are approximately 0, meaning that we are strongly confident on our predicted slopes. We could see that index_education and index_home_security have a weak negative relationship with crime index, while index_health_care has a weak positive relationship with the crime index. A one unit increase of index_education will decrease crime index by 0.3174 on average; a one unit increase of index_home_security will decrease crime index by 1.0730 on average; a one unit increase of index_health_care will increase crime index by 0.9732 on average. Though the model is statistically and economically significant, the weak relationships with either positive or negative signs between our independent variables and dependent variables indicate that there might not be a strong negative correlation between them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From all of the above linear regression models, we have found both positive and negative correlations between our independent and dependent variables, with the slope ranging from -1.4491 to 1.8137. Since all observed slopes are relatively close to 0, the models fail to suggest a strong one-directional relationship. Besides, the R-squared values in all linear regression models are extremely small. Therefore, only applying the linear regression model is not sufficient to explain the actual relationship between the variables of our interest. That being said, for further analysis on the topic, we decide to apply the sklearn to get a more precise prediction on our data. Specifically, we will use linear regression, radial basis function from support vector regression, polynomial from support vector regression, ridge regression, and Poisson regression to predict the crime rate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following scripts, we first split the data into training and testing sets, 80% and 20% respectively. We then use the SVM command to train the data using different regression models, including linear regression, RBF regression, polynomial regression, ridge regression, and Poisson regression. We plotted three blocks of regression models (with independent variables as index_heath_care, index_education, index_home_security_system_svcs), each block with plots on both the training set and testing set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# decide the proportion of training and testing data\n",
    "svm_df = df[[\"index_health_care\", \"index_education\", \"index_home_security_system_svcs\", \"total_crime_index\"]]\n",
    "svm_df_test = pd.DataFrame()\n",
    "svm_df_test = svm_df[(int(len(svm_df) * 0.8)):]\n",
    "svm_df = svm_df[:(int(len(svm_df) * 0.8))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement the function which get the accuracy of the test result\n",
    "def get_score(clf, x_test, y_test, X, y):\n",
    "    y_predict = clf.predict(x_test)\n",
    "    scores = cross_val_score(clf, X, y, cv=10)\n",
    "    print(\"Accuracy Report:\")\n",
    "    print(\"\\t%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "    print(\"\\tR2 Score: %f0.2\" % r2_score(y_test, y_predict))\n",
    "    print(\"\\tMean Square Error: %f0.2\" % mean_squared_error(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using svm from sklearn to train the data using Linear Regression, RBF Regression, \n",
    "# Polynomial Regression, Ridge Regression, and PossionRegression, and this function is for\n",
    "# compare each spending with total crime index\n",
    "def one_one_compare(s):\n",
    "    X = svm_df['%s' % s].values.reshape(-1,1)\n",
    "    y = svm_df['total_crime_index'].values\n",
    "\n",
    "    model1 = LinearRegression()\n",
    "    lr = model1.fit(X, y)\n",
    "\n",
    "    model2 = SVR(kernel='rbf', C=10, epsilon=10)\n",
    "    svr_rbf = model2.fit(X, y)\n",
    "\n",
    "    model3 = SVR(kernel='poly', degree=2, C=10, epsilon=10)\n",
    "    svr_poly = model3.fit(X, y)\n",
    "    \n",
    "    model4 = Ridge(alpha=1.0)\n",
    "    ridge = model4.fit(X, y)\n",
    "\n",
    "    model5 = PoissonRegressor(alpha=1.0)\n",
    "    poisson = model5.fit(X, y)\n",
    "    \n",
    "    x_range = np.linspace(X.min(), X.max(), 100)\n",
    "\n",
    "# predict the training data\n",
    "    y_lr = model1.predict(x_range.reshape(-1, 1))\n",
    "    y_svr = model2.predict(x_range.reshape(-1, 1))\n",
    "    y_poly = model3.predict(x_range.reshape(-1, 1))\n",
    "    y_ridge = model4.predict(x_range.reshape(-1, 1))\n",
    "    y_poisson = model5.predict(x_range.reshape(-1, 1))\n",
    "    \n",
    "    fig = px.scatter(df, x=svm_df['%s' % s], y=svm_df['total_crime_index'], \n",
    "                     opacity=0.8, color_discrete_sequence=['black'])\n",
    "    \n",
    "# adding the data points into scatter plot\n",
    "    fig.add_traces(go.Scatter(x=x_range, y=y_lr, name='Linear Regression', line=dict(color='green')))\n",
    "    fig.add_traces(go.Scatter(x=x_range, y=y_svr, name='Support Vector Regression - RBF', line=dict(color='red')))\n",
    "    fig.add_traces(go.Scatter(x=x_range, y=y_poly, name='Support Vector Regression - Poly', line=dict(color='blue')))\n",
    "    fig.add_traces(go.Scatter(x=x_range, y=y_ridge, name='Ridge Regression', line=dict(color='yellow')))\n",
    "    fig.add_traces(go.Scatter(x=x_range, y=y_poisson, name='Poisson Regression', line=dict(color='pink')))\n",
    "\n",
    "    fig.update_layout(dict(plot_bgcolor = 'white'))\n",
    "\n",
    "# drawing the regression line\n",
    "    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgrey', \n",
    "                     zeroline=True, zerolinewidth=1, zerolinecolor='lightgrey', \n",
    "                     showline=True, linewidth=1, linecolor='black')\n",
    "\n",
    "    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgrey', \n",
    "                     zeroline=True, zerolinewidth=1, zerolinecolor='lightgrey', \n",
    "                     showline=True, linewidth=1, linecolor='black')\n",
    "\n",
    "    fig.update_layout(title=dict(text=\"Spending vs. Crime, Generating Prediction (epsilon=10, C=10, index)\", \n",
    "                                 font=dict(color='black')))\n",
    "\n",
    "    fig.update_traces(marker=dict(size=3))\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "    X = svm_df_test['%s' % s].values.reshape(-1,1)\n",
    "    y = svm_df_test['total_crime_index'].values\n",
    "    \n",
    "    x_range = np.linspace(X.min(), X.max(), 100)\n",
    "\n",
    "# predict the training data\n",
    "    y_lr = model1.predict(x_range.reshape(-1, 1))\n",
    "    y_svr = model2.predict(x_range.reshape(-1, 1))\n",
    "    y_poly = model3.predict(x_range.reshape(-1, 1))\n",
    "    y_ridge = model4.predict(x_range.reshape(-1, 1))\n",
    "    y_poisson = model5.predict(x_range.reshape(-1, 1))\n",
    "    \n",
    "    fig = px.scatter(df, x=svm_df_test['%s' % s], y=svm_df_test['total_crime_index'], \n",
    "                     opacity=0.8, color_discrete_sequence=['black'])\n",
    "    \n",
    "# adding the data points into scatter plot\n",
    "    fig.add_traces(go.Scatter(x=x_range, y=y_lr, name='Linear Regression', line=dict(color='green')))\n",
    "    fig.add_traces(go.Scatter(x=x_range, y=y_svr, name='Support Vector Regression - RBF', line=dict(color='red')))\n",
    "    fig.add_traces(go.Scatter(x=x_range, y=y_poly, name='Support Vector Regression - Poly', line=dict(color='blue')))\n",
    "    fig.add_traces(go.Scatter(x=x_range, y=y_ridge, name='Ridge Regression', line=dict(color='yellow')))\n",
    "    fig.add_traces(go.Scatter(x=x_range, y=y_poisson, name='Poisson Regression', line=dict(color='pink')))\n",
    "\n",
    "    fig.update_layout(dict(plot_bgcolor = 'white'))\n",
    "\n",
    "# drawing the regression line\n",
    "    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgrey', \n",
    "                     zeroline=True, zerolinewidth=1, zerolinecolor='lightgrey', \n",
    "                     showline=True, linewidth=1, linecolor='black')\n",
    "\n",
    "    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgrey', \n",
    "                     zeroline=True, zerolinewidth=1, zerolinecolor='lightgrey', \n",
    "                     showline=True, linewidth=1, linecolor='black')\n",
    "\n",
    "    fig.update_layout(title=dict(text=\"Spending vs. Crime, Testing Prediction (epsilon=10, C=10, index)\", \n",
    "                                 font=dict(color='black')))\n",
    "\n",
    "    fig.update_traces(marker=dict(size=3))\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# using the function get_score to print out the accuracy of each model\n",
    "    get_score(lr, svm_df_test['%s' % s].values.reshape(-1,1), svm_df_test['total_crime_index'].values, X, y)\n",
    "    get_score(svr_rbf, svm_df_test['%s' % s].values.reshape(-1,1), svm_df_test['total_crime_index'].values, X, y)\n",
    "    get_score(svr_poly, svm_df_test['%s' % s].values.reshape(-1,1), svm_df_test['total_crime_index'].values, X, y)\n",
    "    get_score(ridge, svm_df_test['%s' % s].values.reshape(-1,1), svm_df_test['total_crime_index'].values, X, y)\n",
    "    get_score(poisson, svm_df_test['%s' % s].values.reshape(-1,1), svm_df_test['total_crime_index'].values, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "one_one_compare('index_health_care')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the plot of index_heath_care vs. index_crime, we found that while all regression models fail to represent our training data perfectly due to the large spread of the data points, the RBF regression model fits our training data the best among all. Besides, all regression models display a clear decreasing trend, indicating that as the spending on health care increases, the crime rate decreases. Although this observation matches what we observed in the OLS regression results (a very weak negative relationship between independent and dependent variables), it is obvious that all of the regression models have low accuracy on the training data.\n",
    "In a similar manner, if we take a closer look at the regression model plot on the testing data, we can observe that again all regression models display a clear decreasing trend, indicating that as the spending on health care increases, the crime rate decreases. Nevertheless, since the testing set only contains 20% of the data, the data points in the plot are even more spread out, leading to an even less accurate prediction of our regression models. Apart from that, the Accuracy Report below the plots states that the accuracy scores for all regression models are negative, ranging from -0.22 to -0.11, whereas the R2 scores are also negative, ranging from approximately -0.29 to -0.20. Even worse, the mean squared error values for all regression models are also extremely high (around 1,000). As a result, since both the training models and testing models are inaccurate (with accuracy, R2 scores below 0, and mean squared error about 1,000), we have concluded that there does not exist a relationship between health care spending and crime rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_one_compare('index_education')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the plot of index_education vs. index_crime, we found that while all regression models fail to represent our training data perfectly due to the large spread of the data points, the RBF regression model fits our training data the best among all. Besides, all regression models display a clear decreasing trend, indicating that as the spending on education increases, the crime rate decreases. Although this observation matches what we observed in the OLS regression results (a very weak negative relationship between independent and dependent variables), it is obvious that all of the regression models have low accuracy on the training data.\n",
    "In a similar manner, if we take a closer look at the regression model plot on the testing data, we can observe that again all regression models display a clear decreasing trend, indicating that as the spending on education increases, the crime rate decreases. Nevertheless, since the testing set only contains 20% of the data, the data points in the plot are even more spread out, leading to an even less accurate prediction of our regression models. Apart from that, the Accuracy Report below the plots states that the accuracy scores for all regression models are negative, ranging from -0.21 to -0.12, whereas the R2 scores are also negative, ranging from approximately -0.25 to -0.11. Even worse, the mean squared error values for all regression models are also extremely high (around 1,000). As a result, since both the training models and testing models are inaccurate (with accuracy, R2 scores below 0, and mean squared error about 1,000), we have concluded that there does not exist a relationship between education spending and crime rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "one_one_compare('index_home_security_system_svcs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the plot of index_home_security_system_svcs vs. index_crime, we found that while all regression models fail to represent our training data perfectly due to the large spread of the data points, the RBF regression model fits our training data the best among all. Besides, all regression models display a clear decreasing trend, indicating that as the spending on home security system services increases, the crime rate decreases. Although this observation matches what we observed in the OLS regression results (a very weak negative relationship between independent and dependent variables), it is obvious that all of the regression models have low accuracy on the training data.\n",
    "In a similar manner, if we take a closer look at the regression model plot on the testing data, we can observe that again all regression models display a clear decreasing trend, indicating that as the spending on home security system services increases, the crime rate decreases. Nevertheless, since the testing set only contains 20% of the data, the data points in the plot are even more spread out, leading to an even less accurate prediction of our regression models. Apart from that, the Accuracy Report below the plots states that the accuracy scores for all regression models are negative, ranging from -0.20 to -0.12, whereas the R2 scores are also negative, ranging from approximately -0.35 to -0.24. Even worse, the mean squared error values for all regression models are also extremely high (around 1,000). As a result, since both the training models and testing models are inaccurate (with accuracy, R2 scores below 0, and mean squared error about 1,000), we have concluded that there does not exist a relationship between home security system services spending and crime rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using svm from sklearn to train the data using Linear Regression, RBF Regression, \n",
    "# Polynomial Regression, Ridge Regression, and PossionRegression, and this function is for\n",
    "# compare two of the spendings with total crime index\n",
    "\n",
    "def two_one_compare(s1, s2):\n",
    "    fig = px.scatter_3d(svm_df, \n",
    "                        x=svm_df['%s' % s1], \n",
    "                        y=svm_df['%s' % s2], \n",
    "                        z=svm_df['total_crime_index'], \n",
    "                        opacity=0.8, color_discrete_sequence=['black'],\n",
    "                        height=900, width=900)\n",
    "\n",
    "    fig.update_layout(title_text=\"Scatter 3D Plot\",\n",
    "                      scene_camera_eye=dict(x=1.5, y=1.5, z=0.25), \n",
    "                      scene_camera_center=dict(x=0, y=0, z=-0.2),\n",
    "                      scene = dict(xaxis=dict(backgroundcolor='white',\n",
    "                                              color='black',\n",
    "                                              gridcolor='lightgrey'),\n",
    "                                   yaxis=dict(backgroundcolor='white',\n",
    "                                              color='black',\n",
    "                                              gridcolor='lightgrey'\n",
    "                                              ),\n",
    "                                   zaxis=dict(backgroundcolor='white',\n",
    "                                              color='black', \n",
    "                                              gridcolor='lightgrey')))\n",
    "\n",
    "    fig.update_traces(marker=dict(size=2))\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    X=svm_df[['%s' % s1,'%s' % s2]]\n",
    "    y=svm_df['total_crime_index'].values\n",
    "\n",
    "# declare 5 models to train the data\n",
    "    model1 = LinearRegression()\n",
    "    lr = model1.fit(X, y)\n",
    "\n",
    "    model2 = SVR(kernel='rbf', C=10, epsilon=1)\n",
    "    svr_rbf = model2.fit(X, y)\n",
    "\n",
    "    model3 = SVR(kernel='poly', degree=2, C=10, epsilon=1)\n",
    "    svr_poly = model3.fit(X, y)\n",
    "    \n",
    "    model4 = Ridge(alpha=1.0)\n",
    "    ridge = model4.fit(X, y)\n",
    "\n",
    "    model5 = PoissonRegressor(alpha=1.0)\n",
    "    poisson = model5.fit(X, y)\n",
    "\n",
    "    mesh_size = 0.5\n",
    "\n",
    "    x_min, x_max = X['%s' % s1].min(), X['%s' % s1].max()\n",
    "    y_min, y_max = X['%s' % s2].min(), X['%s' % s2].max()\n",
    "\n",
    "    xrange = np.arange(x_min, x_max, mesh_size)\n",
    "    yrange = np.arange(y_min, y_max, mesh_size)\n",
    "    xx, yy = np.meshgrid(xrange, yrange)\n",
    "    \n",
    "# predicting the training data in linear regression\n",
    "    pred_lr = model1.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    pred_lr = pred_lr.reshape(xx.shape)\n",
    "\n",
    "# predicting the training data in RBF regression\n",
    "    pred_svr_rbf = model2.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    pred_svr_rbf = pred_svr_rbf.reshape(xx.shape)\n",
    "\n",
    "# predicting the training data in polynomial regression\n",
    "    pred_svr_poly = model3.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    pred_svr_poly = pred_svr_poly.reshape(xx.shape)\n",
    "    \n",
    "# predicting the training data in ridge regression\n",
    "    pred_ridge = model4.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    pred_ridge = pred_ridge.reshape(xx.shape)\n",
    "    \n",
    "# predicting the training data in poisson regression\n",
    "    pred_poisson = model5.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    pred_poisson = pred_poisson.reshape(xx.shape)\n",
    "\n",
    "    fig = px.scatter_3d(svm_df, x=svm_df['%s' % s1], \n",
    "                        y=svm_df['%s' % s2], \n",
    "                        z=svm_df['total_crime_index'],\n",
    "                        opacity=0.8, color_discrete_sequence=['black'],\n",
    "                        height=900, width=900)\n",
    "\n",
    "    fig.update_layout(title_text=\"Scatter 3D Plot with Regression Prediction Surfaces, Generating Prediction\",\n",
    "                      scene_camera_eye=dict(x=1.5, y=1.5, z=0.25), \n",
    "                      scene_camera_center=dict(x=0, y=0, z=-0.2),\n",
    "                      scene = dict(xaxis=dict(backgroundcolor='white',\n",
    "                                              color='black',\n",
    "                                              gridcolor='lightgrey'),\n",
    "                                   yaxis=dict(backgroundcolor='white',\n",
    "                                              color='black',\n",
    "                                              gridcolor='lightgrey'\n",
    "                                              ),\n",
    "                                   zaxis=dict(backgroundcolor='white',\n",
    "                                              color='black', \n",
    "                                              gridcolor='lightgrey')))\n",
    "\n",
    "    fig.update_traces(marker=dict(size=2))\n",
    "    \n",
    "    fig.add_traces(go.Surface(x=xrange, y=yrange, z=pred_lr, name='lr', \n",
    "                              colorscale=px.colors.sequential.Greens, showscale=False))\n",
    "\n",
    "    fig.add_traces(go.Surface(x=xrange, y=yrange, z=pred_svr_rbf, name='rbf', \n",
    "                              colorscale=px.colors.sequential.Reds, showscale=False))\n",
    "    \n",
    "    fig.add_traces(go.Surface(x=xrange, y=yrange, z=pred_svr_poly, name='poly', \n",
    "                              colorscale=px.colors.sequential.Blues, showscale=False))\n",
    "    \n",
    "    fig.add_traces(go.Surface(x=xrange, y=yrange, z=pred_ridge, name='ridge', \n",
    "                              colorscale=px.colors.sequential.YlOrBr, showscale=False))\n",
    "    \n",
    "    fig.add_traces(go.Surface(x=xrange, y=yrange, z=pred_poisson, name='poisson', \n",
    "                              colorscale=px.colors.sequential.Purpor, showscale=False))\n",
    "    \n",
    "    fig.update_traces(showlegend=True, selector=dict(type='surface'))\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "# prediction model\n",
    "    X=svm_df_test[['%s' % s1,'%s' % s2]]\n",
    "    y=svm_df_test['total_crime_index'].values\n",
    "    \n",
    "    x_min, x_max = X['%s' % s1].min(), X['%s' % s1].max()\n",
    "    y_min, y_max = X['%s' % s2].min(), X['%s' % s2].max()\n",
    "\n",
    "    xrange = np.arange(x_min, x_max, mesh_size)\n",
    "    yrange = np.arange(y_min, y_max, mesh_size)\n",
    "    xx, yy = np.meshgrid(xrange, yrange)\n",
    "    \n",
    "# predicting the training data in linear regression\n",
    "    pred_lr = model1.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    pred_lr = pred_lr.reshape(xx.shape)\n",
    "\n",
    "# predicting the training data in RBF regression\n",
    "    pred_svr_rbf = model2.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    pred_svr_rbf = pred_svr_rbf.reshape(xx.shape)\n",
    "\n",
    "# predicting the training data in polynomial regression\n",
    "    pred_svr_poly = model3.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    pred_svr_poly = pred_svr_poly.reshape(xx.shape)\n",
    "    \n",
    "# predicting the training data in ridge regression\n",
    "    pred_ridge = model4.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    pred_ridge = pred_ridge.reshape(xx.shape)\n",
    "    \n",
    "# predicting the training data in poisson regression\n",
    "    pred_poisson = model5.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    pred_poisson = pred_poisson.reshape(xx.shape)\n",
    "\n",
    "    fig = px.scatter_3d(svm_df, x=svm_df_test['%s' % s1], \n",
    "                        y=svm_df_test['%s' % s2], \n",
    "                        z=svm_df_test['total_crime_index'],\n",
    "                        opacity=0.8, color_discrete_sequence=['black'],\n",
    "                        height=900, width=900)\n",
    "\n",
    "    fig.update_layout(title_text=\"Scatter 3D Plot with Regression Prediction Surfaces, Prediction Results\",\n",
    "                      scene_camera_eye=dict(x=1.5, y=1.5, z=0.25), \n",
    "                      scene_camera_center=dict(x=0, y=0, z=-0.2),\n",
    "                      scene = dict(xaxis=dict(backgroundcolor='white',\n",
    "                                              color='black',\n",
    "                                              gridcolor='lightgrey'),\n",
    "                                   yaxis=dict(backgroundcolor='white',\n",
    "                                              color='black',\n",
    "                                              gridcolor='lightgrey'\n",
    "                                              ),\n",
    "                                   zaxis=dict(backgroundcolor='white',\n",
    "                                              color='black', \n",
    "                                              gridcolor='lightgrey')))\n",
    "\n",
    "    fig.update_traces(marker=dict(size=2))\n",
    "    \n",
    "    fig.add_traces(go.Surface(x=xrange, y=yrange, z=pred_lr, name='lr', \n",
    "                              colorscale=px.colors.sequential.Greens, showscale=False))\n",
    "\n",
    "    fig.add_traces(go.Surface(x=xrange, y=yrange, z=pred_svr_rbf, name='rbf', \n",
    "                              colorscale=px.colors.sequential.Reds, showscale=False))\n",
    "    \n",
    "    fig.add_traces(go.Surface(x=xrange, y=yrange, z=pred_svr_poly, name='poly', \n",
    "                              colorscale=px.colors.sequential.Blues, showscale=False))\n",
    "    \n",
    "    fig.add_traces(go.Surface(x=xrange, y=yrange, z=pred_ridge, name='ridge', \n",
    "                              colorscale=px.colors.sequential.YlOrBr, showscale=False))\n",
    "    \n",
    "    fig.add_traces(go.Surface(x=xrange, y=yrange, z=pred_poisson, name='poisson', \n",
    "                              colorscale=px.colors.sequential.Purpor, showscale=False))\n",
    "    \n",
    "    fig.update_traces(showlegend=True, selector=dict(type='surface'))\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "# using the get_score to print out the accuracy of model\n",
    "    get_score(lr, svm_df_test[['%s' % s1,'%s' % s2]], svm_df_test['total_crime_index'].values, X, y)\n",
    "    get_score(svr_rbf, svm_df_test[['%s' % s1,'%s' % s2]], svm_df_test['total_crime_index'].values, X, y)\n",
    "    get_score(svr_poly, svm_df_test[['%s' % s1,'%s' % s2]], svm_df_test['total_crime_index'].values, X, y)\n",
    "    get_score(ridge, svm_df_test[['%s' % s1,'%s' % s2]], svm_df_test['total_crime_index'].values, X, y)\n",
    "    get_score(poisson, svm_df_test[['%s' % s1,'%s' % s2]], svm_df_test['total_crime_index'].values, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to previous analysis, we assign two of the variables in [healthcare, education, and home security] and build regression models based on combinations of two independent variables. Similarly, we split our data into 80% as training data and 20% as testing data. For convenience, we wrote a function to show the 3d distribution of data, training data with its prediction line, and testing data with its prediction results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "two_one_compare('index_health_care','index_education')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first analyze the relationship of index health care and index education. From the first graph, we could see the distribution of data is randomly separated. From the second graph, we found that our regression prediction surfaces, though aligned with a lot of data, there are still large numbers of data not on the surfaces. Similarly, in the last graph, though the number of data not on the surfaces decreases, the total number of data presented on the graph decreases as well because we only present 20% of testing data in the third graph. The accuracy report coordinates with our conclusion since each model has an R2 score that is all below 0 with huge mean squared error (around 1000) and low accuracy. Thus, we claim that there does not exist a relationship between index health care and index education.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "two_one_compare('index_education','index_home_security_system_svcs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then analyze the relationship of index home security and index education. From the first graph, we could see the distribution of data is randomly separated. From the second graph, we found that our regression prediction surfaces, though aligned with a lot of data, there are still large numbers of data not on the surfaces. Similarly, in the last graph, though the number of data not on the surfaces decreases, the total number of data presented on the graph decreases as well because we only present 20% of testing data in the third graph. The accuracy report coordinates with our conclusion since each model has an R2 score that is all below 0 with huge mean squared error (around 1000) and low accuracy. Thus, we claim that there does not exist a relationship between index home security and index education.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "two_one_compare('index_home_security_system_svcs','index_health_care')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we analyze the relationship of index home security and index health care. From the first graph, we could see the distribution of data is randomly separated. From the second graph, we found that our regression prediction surfaces, though aligned with a lot of data, there are still large numbers of data not on the surfaces. Similarly, in the last graph, though the number of data not on the surfaces decreases, the total number of data presented on the graph decreases as well because we only present 20% of testing data in the third graph. The accuracy report coordinates with our conclusion since each model has an R2 score that is all below 0 with huge mean squared error (around 1000) and low accuracy. Thus, we claim that there does not exist a relationship between index home security and index education.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare 5 models to train the data \n",
    "X=svm_df[['index_health_care','index_education','index_home_security_system_svcs']]\n",
    "y=svm_df['total_crime_index'].values\n",
    "\n",
    "model1 = LinearRegression()\n",
    "lr = model1.fit(X, y)\n",
    "\n",
    "model2 = SVR(kernel='rbf', C=10, epsilon=1)\n",
    "svr_rbf = model2.fit(X, y)\n",
    "\n",
    "model3 = SVR(kernel='poly', degree=2, C=10, epsilon=1)\n",
    "svr_poly = model3.fit(X, y)\n",
    "    \n",
    "model4 = Ridge(alpha=1.0)\n",
    "ridge = model4.fit(X, y)\n",
    "\n",
    "model5 = PoissonRegressor(alpha=1.0)\n",
    "poisson = model5.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# using 3D model to draw the 3 spendings to total crime index graphs\n",
    "fig = px.scatter_3d(svm_df, x=svm_df['index_health_care'], \n",
    "                    y=svm_df['index_education'], \n",
    "                    z=svm_df['index_home_security_system_svcs'],\n",
    "                    color=svm_df['total_crime_index'],\n",
    "                    opacity=0.8, color_discrete_sequence=['black'],\n",
    "                    height=900, width=900)\n",
    "\n",
    "fig.update_layout(title_text=\"Scatter 3D Plot for all three factors\",\n",
    "                      scene_camera_eye=dict(x=1.5, y=1.5, z=1.5), \n",
    "                      scene_camera_center=dict(x=0, y=0, z=0),\n",
    "                      scene = dict(xaxis=dict(backgroundcolor='white',\n",
    "                                              color='black',\n",
    "                                              gridcolor='lightgrey'),\n",
    "                                   yaxis=dict(backgroundcolor='white',\n",
    "                                              color='black',\n",
    "                                              gridcolor='lightgrey'),\n",
    "                                   zaxis=dict(backgroundcolor='white',\n",
    "                                              color='black', \n",
    "                                              gridcolor='lightgrey')))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to further visualize the correlation between education index, healthcare index, home security index, and total crime index, we draw the 3D graph where x, y, z represents education index, healthcare index, home security index and color represents total crime index. From the graph, we can easily find that every data is randomly separated and we cannot find a specific trend among these data. \n",
    "Our data supports our finds. From accuracy reports, we find that each model has an R2 score that is all below 0 with huge mean squared error (over 1000). Besides, the accuracy of each model is very low. Thus, we have concluded that there does not exist a relationship between education index, healthcare index, home security index, and total crime rate index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the get_score function to print out the accuracy of each model\n",
    "get_score(lr, svm_df_test[['index_health_care','index_education','index_home_security_system_svcs']], svm_df_test['total_crime_index'].values, X, y)\n",
    "get_score(svr_rbf, svm_df_test[['index_health_care','index_education','index_home_security_system_svcs']], svm_df_test['total_crime_index'].values, X, y)\n",
    "get_score(svr_poly, svm_df_test[['index_health_care','index_education','index_home_security_system_svcs']], svm_df_test['total_crime_index'].values, X, y)\n",
    "get_score(ridge, svm_df_test[['index_health_care','index_education','index_home_security_system_svcs']], svm_df_test['total_crime_index'].values, X, y)\n",
    "get_score(poisson, svm_df_test[['index_health_care','index_education','index_home_security_system_svcs']], svm_df_test['total_crime_index'].values, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) The Question\n",
    "- Health spending and crime are fundamental aspects of society that many other scholars have studied throughout human history. We believe that our question is well-posed and explainable.\n",
    "- Every member in the group had taken courses such as WCWP, DOC, MATH, and ECON series. We believe that we have enough knowledge in environmental justice, community resources balancing, basic economics, statistics, and other areas to finish the analysis.\n",
    "- The scope for this problem is pretty narrow - San Deigo County health spending data and San Deigo County crime data. Nevertheless, it is still possible to find other correlations, for example, the correlation between the robbery index and the burglary index. In other words, is there a relationship between robbery rates and burglary rates?\n",
    "\n",
    "2) The Implications\n",
    "- The stakeholders are residents in San Diego County. The latter took the Census or responded to any other type of survey. We believe that the basic Ethnics and Privacy policies are explained and executed at the Census or the survey. Also, all possible Personal Identification Information (PII) is removed from ArcGIS's data and Census data. Thus, we assume that the analysis will not influence the stakeholder.\n",
    "- Since all data are public on ArcGis. Meanwhile, Esri is regulated by multiple organizations and Governments. Also, there exist many similar types of research already. Thus, we believe that our work will not produce a nefarious purpose.\n",
    "- We have read related reports and similar research so that there should be no unintended consequences.\n",
    "\n",
    "3) The Data\n",
    "- All direct and relevant data can be obtained on the ArcGIS public database.\n",
    "- There existed multiple categorized data for both areas, which is more than enough.\n",
    "- We will use multiple categories and different test methods (mathematical models) to create different data frames to eliminate biases. However, because we do not collect the data, we cannot make sure that the data itself does not have biased. Also, the Census might have biases in its design and purpose population. However, we believe the Federal Government and ArcGIS tried their best to reduce the biases of its data.\n",
    "- Moreover, all of the datasets we use are objective, and therefore no subjective biases exist.\n",
    "\n",
    "4) Informed Consent\n",
    "- All participants who participated have given consent to the Census or any previous surveys in the past. ArcGIS and Esri both ask permission and consent from their participants.\n",
    "- The data collection process from ArcGIS or other organizations may have some issues on informed consent. However, we did not know the details of their data collections process. Therefore would not comment more on that.\n",
    "\n",
    "5) Privacy\n",
    "- All PIIs were already removed from the datasets by ArcGIS and United States government.\n",
    "- All data are correctly stored in ArcGIS online, and they can be accessed freely online with the online visualization system.\n",
    "- Since all data is public, we believe it will not be vulnerable.\n",
    "- The data collection process from ArcGIS or other organizations may have some privacy issues. However, we did not know the details of their data collections process. Therefore would not comment more on that.\n",
    "\n",
    "6) Evaluation\n",
    "- We will be using multiple models and different data from datasets to create a different data frame. Multiple mathematical tests will be used as well.\n",
    "- The success metric should measure and compare multiple results from the different mathematical testing models with different data frames. If similar patterns are found with the same type of data, then we will assume that the metric of success is achieved.\n",
    "\n",
    "7) Analysis\n",
    "- We will not change anything from the data or the analysis to verify our hypothesis or create better associations and results.\n",
    "- We will use appropriate metrics to make our results more understandable and explain any limitations or shortcomings.\n",
    "- No discriminative terms are used in the datasets we used. Also, we will use variables that are not discriminatory to protect fairness among groups.\n",
    "- We will use multiple categories of data to create different models. Thus, the relationship between two prominent aspects will turn into small correlations.\n",
    "- We believe the health spending and crime rate are not directly related. Thus the data should be proxies. Thus, we might use intermediate data and find covariates between all data types.\n",
    "\n",
    "8) Transparency and Appeal\n",
    "- We will show all of our data with integrity and honesty. Although we might manipulate its presentation format, all data will be presented.\n",
    "- We will show all of our mathematical models, including the graph, codes, and other definitions. Word explanations are also used for explanations. Exact words and explanations will be used, and they can be understood easily.\n",
    "- For interpretable models, it should be easy to understand as well as to test. Also, multiple models will be used to eliminate unreasonable models.\n",
    "- We will use well-known and mathematical supported models.\n",
    "\n",
    "9) Continuous Monitoring\n",
    "- We will update the data frequently to be up to date from the online database.\n",
    "- We will list limitations and potential improvements at the end of our research.\n",
    "- We believe our research will only reveal the relationship, instead not state an assumption.\n",
    "- When new models or algorithms come out, we will update the data.\n",
    "- We always pay attention to the Ethnics aspect before applying any models or decisions.\n",
    "- If we find out that the research harmed any groups or individuals, we will immediately withdraw our study and revise or delete related data.\n",
    "- We will make a precise, strong statement of the purpose of this research so that it will not be misused in any way or form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall our research question:\n",
    "\n",
    "#### Is there a relationship between health, education, and house security spending and all different categories of crime rates in all 441 valid FSIP areas in San Diego County?\n",
    "\n",
    "And hypothesis:\n",
    "\n",
    "#### The higher the average household health / education / home security system spending the sector has, the lower the crime rate sector has.\n",
    "\n",
    "Now we would like to make a comprehensive conclusion on the relationship between health care, education, and home security system spending and crime rate. In the above analysis, we created regression models on different variables using ordinary least squares and visualized the relationship between them using a scatter plot. However, from all of the linear regression models, we have found both positive and negative correlations between our independent and dependent variables, indicating that there does not appear to be a clear one-directional relationship. Thus, for further analysis, we applied the sklean and created different regression models including linear regression, radial basis function from support vector regression, polynomial from support vector regression, ridge regression, and Poisson regression to predict the relationship between our variables of interest. Unfortunately, we have determined negative accuracy and R2 scores for all these regression models as well as the relatively high mean squared error (about 1,000). Therefore, we cannot derive a relationship from the above analyses. We have reached to the conclusion that there is no significant relationship between health care, education, home security spending, and the crime rate.\n",
    "\n",
    "#### Limitation of our model:\n",
    "Our analysis basically concluded that there are no clear relationships between our independent variables and dependent variables. However, some inevitable limitations of our research do exist. Firstly, since San Diego county is a relatively small area, we only have a limited amount of data, which might make our models not representative of the true relationship between independent variables and dependent variable. Secondly, our OLS model might not be 100 percent accurate due to omitted variable bias. The bias exists because other variables will affect crime rate and are correlated with either education, health, or home security at the same time. Those outside variables might affect the crime rate and either move along the same direction/different direction with our independent variables, causing our OLS models to overestimate/underestimate the true effects of each variable. The dependent variables and independent varibles might also be interrelated, causing the slope coefficients to be inaccurate. Thirdly, we cannot determine whether it is a type 1 error or type 2 error. Although some of our models indicate a weak negative relationship between our independent variables and dependent variables, our R square is fairly low, which means the majority of our data cannot be explained by the OLS models. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Jiahui Cai: analysis of OLS, data cleaning, drawing distribution graph for EDA, analysis and conclusion text\n",
    "- Jacky Hu: data cleaning, drawing distribution graph for EDA, implement function for graphing\n",
    "- Cody Li: ethnic, data set, sklearn statistic model and graphing (everything after OLS)\n",
    "- Rosy Xu: data clean (outlier and graph), drawing distribution graph for EDA, analysis and conclusion text\n",
    "- Linghao Zhang: analysis and conclusion text, and nearly all other texts\n",
    "\n",
    "- Everyone: inline comments, decide the general direction during the project, give suggestions, doing presentation, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1) We are expected to meet twice a week for discussion.\n",
    "- 2) Usually, we discuss what will be done for the week on Monday or Tuesday, then each group member finishes his or her part during the rest of the week.\n",
    "- 3) One final meeting will be on Wednesday night before 8 PM so that any leftover can be done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/20  | 10 AM | Read & Think about COGS 108 expectations; brainstorm topics/questions  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 1/26  | 2 PM  |  Do background research on topic | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 2/1   | 9 AM  | Search for datasets; data cleaning | find OLS model   |\n",
    "| 2/14  | 8 PM  | try to analysis the OLS model | finishing OLS model and write analysis   |\n",
    "| 2/23  | 8 PM  | finishing OLS | try to find more models|\n",
    "| 3/13  | 3 PM  | Finishing the final project | Complete video and powerpoint |\n",
    "| 3/14  | Before 11:59 PM  | NA | Turn in Final Project & Group Project Surveys |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
